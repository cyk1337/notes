<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/notes/images/dog.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/notes/images/dog.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/notes/images/dog.png">
  <link rel="mask-icon" href="/notes/images/dog.png" color="#222">

<link rel="stylesheet" href="/notes/css/main.css">


<link rel="stylesheet" href="/notes/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"cyk1337.github.io","root":"/notes/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":{"disqus":{"text":"Load Disqus","order":-1}}},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Name Entity Recognition (NER) labels sequences of words in a text which are the names of things, such as person and company names, or gene and protein names.">
<meta property="og:type" content="article">
<meta property="og:title" content="Named Entity Recognition Overview">
<meta property="og:url" content="https://cyk1337.github.io/notes/2018/11/29/NLP/NER/NER-overview/index.html">
<meta property="og:site_name" content="Yekun&#39;s Note">
<meta property="og:description" content="Name Entity Recognition (NER) labels sequences of words in a text which are the names of things, such as person and company names, or gene and protein names.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/HMM.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/MaxEnt.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/bilstm-crf.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/stack-LSTM.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/ID-CNNs.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/BERT-NER.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/char-lstm.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/word-lstm.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/lattice-lstm-2.png">
<meta property="og:image" content="https://cyk1337.github.io/notes/images/lattice-lstm.png">
<meta property="article:published_time" content="2018-11-29T10:24:10.000Z">
<meta property="article:modified_time" content="2018-11-29T10:24:10.000Z">
<meta property="article:author" content="Yekun Chai">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="Survey">
<meta property="article:tag" content="NER">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cyk1337.github.io/notes/images/HMM.png">

<link rel="canonical" href="https://cyk1337.github.io/notes/2018/11/29/NLP/NER/NER-overview/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Named Entity Recognition Overview | Yekun's Note</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/notes/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Yekun's Note</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Machine learning notes and writeup.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="https://cyk1337.github.io/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-blog">

    <a href="/notes/" rel="section"><i class="fa fa-rss-square fa-fw"></i>Blog</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/notes/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/notes/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <!-- chaiyekun added -->
    <a target="_blank" rel="noopener" href="https://github.com/cyk1337"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_red_aa0000.png?resize=149%2C149" alt="Fork me on GitHub"></a>
    <!-- 
    <a target="_blank" rel="noopener" href="https://github.com/cyk1337"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_red_aa0000.png" alt="Fork me on GitHub"></a>
    -->

    <!-- (github fork span, top right)
    <a target="_blank" rel="noopener" href="https://github.com/cyk1337"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>
    -->
    <!-- (github fork span)
      <a target="_blank" rel="noopener" href="https://github.com/cyk1337" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#64CEAA; color:#fff; position: absolute; top: 0; border: 0; left: 0; transform: scale(-1, 1);" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    -->

    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://cyk1337.github.io/notes/2018/11/29/NLP/NER/NER-overview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes/images/ernie.jpeg">
      <meta itemprop="name" content="Yekun Chai">
      <meta itemprop="description" content="Language is not just words.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yekun's Note">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Named Entity Recognition Overview
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-29 18:24:10" itemprop="dateCreated datePublished" datetime="2018-11-29T18:24:10+08:00">2018-11-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/notes/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/notes/categories/NLP/Sequence-labeling/" itemprop="url" rel="index"><span itemprop="name">Sequence labeling</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/notes/categories/NLP/Sequence-labeling/NER/" itemprop="url" rel="index"><span itemprop="name">NER</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/notes/2018/11/29/NLP/NER/NER-overview/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/11/29/NLP/NER/NER-overview/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/hint.css/2.6.0/hint.min.css"><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p><strong>Name Entity Recognition</strong> (NER) labels sequences of words in a text which are the names of things, such as person and company names, or gene and protein names.</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<span id="more"></span>
<p>Approaches:</p>
<ul>
<li>Statistical ML methods: HMM, MEMM, CRF</li>
<li>Deep learning methods: RNN-CRF, CNN-CRF</li>
</ul>
<hr>
<h1 id="Hidden-Markov-Model"><a href="#Hidden-Markov-Model" class="headerlink" title="Hidden Markov Model"></a>Hidden Markov Model</h1><p><img data-src="/notes/images/HMM.png" alt="HMM"></p>
<p>HMM consists of a discrete-time, discrete-state Markov chain, with hidden states $z_t \in {1,…,K} $<br>, plus an observation model $p(\mathbf{x}_t|z_t)$. </p>
<p>HMM is a <strong>generative model</strong> that optimises the likelihood $P(W|T)$, consisting of three components: </p>
<ul>
<li>Initial probability $\pmb{\pi}$</li>
<li>Transition probability matrix $\pmb{A}$</li>
<li>Emission probability matrix $\pmb{B}$. </li>
</ul>
<p>The joint distribution is:</p>
<script type="math/tex; mode=display">p( \mathbf{z}_{1:T}, \mathbf{x}_{1:T}) =p( \mathbf{z}_{1:T}) p( \mathbf{x}_{1:T}| \mathbf{z}_{1:T}) = \underbrace{p(z_1)}_{\pmb{\pi}} \underbrace{\prod_{t=2}^T p(z_t|z_{t-1})}_{\pmb{A}} \underbrace{[\prod_{t=1}^T p(\mathbf{x}_t|z_t)]}_{\pmb{B}}</script><p>We estimate the posterior by combining the likelihood and the prior P(T).</p>
<script type="math/tex; mode=display">\hat{T} = \mathop{\arg\max}_T P(T|W) \\  = \mathop{\arg\max}_T P(W|T) P(T) \\ = \mathop{\arg\max}_T \underbrace{\prod_i P(\textrm{word}_i | \textrm{tag}_i)}_\textrm{emission probability} \underbrace{\prod_i P(\textrm{tag}_i|tag_{i-1})}_\textrm{transmission probability}</script><p>HMM states only conditions on the previous state.</p>
<div class="note danger">
            <p><strong>HMM cons</strong>: Independence assumptions.</p>
          </div>
<h1 id="Maximum-Entropy-Markov-Model-MEMM"><a href="#Maximum-Entropy-Markov-Model-MEMM" class="headerlink" title="Maximum-Entropy Markov Model (MEMM)"></a>Maximum-Entropy Markov Model (MEMM)</h1><div class="note info">
            <p>HMM based on the probabilities of transmission probability matrix and emission probability matrix. It is <strong>hard to encode the knowledge</strong> into these two matrices. If we include many knowledge sources, like capitalisation, the presence of hyphens, word endings. It is not easy to fit the probability like $P(\textrm{capitalisation} | \textrm{tag}), P(\textrm{hyphen} | \textrm{tag}), P(\textrm{suffix} | \textrm{tag}), P(\textrm{suffix} | \textrm{tag})$ into an HMM-style model.</p><p>HMM assumes the independence between observations $z$, while MEMM does not. However, MEMM suffers from the label bias problem.</p>
          </div>
<p><img data-src="/notes/images/MaxEnt.png" alt="MEMM"></p>
<p>MEMM is a <strong>discriminative model</strong>. It computes the <em>posterior</em> $P(Z=T|X=W)$ directly. MEMM states conditioned on the <em>previous state</em> and <em>current observation</em>.</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(Z \vert X) &{}= \prod_{t=1}^T p(z_t \vert x_t, z_{t-1}) \\
&{}= \prod_{t=1}^T \frac{1}{Z(x_t, z')} \exp \bigg( \sum_t \lambda_t f(x_t, z_t) \bigg)
\end{aligned}</script><p>where $f{\cdot}$ is real-valued feature functions, $Z$ is a normalization term.</p>
<p>Thus, </p>
<script type="math/tex; mode=display">\hat{T} = \mathop{\arg\max}_T P(T|W) \\ =  \mathop{\arg\max}_T \prod_i P(\textrm{tag}_i | \textrm{word}_i, \textrm{tag}_{i-1})</script><p><strong>Decoding</strong>: Viterbi algorithm.</p>
<p><strong>Pros over HMM</strong>: offer increased freedom in choosing features to represent obervations.</p>
<ul>
<li><del>Strict left-to-right word classifier</del>. </li>
<li>Cons: only use left sequence information. It cannot consider future sequence information.</li>
</ul>
<div class="note danger">
            <p><strong>MEMM weakness</strong>: </p><ul><li><strong>Label bias</strong> problem: states with low-entropy transition distributions “effectively ignore their observations”. MEMM normalizes over the set of possible output labels at each time step, which is <strong>locally normalized</strong>. “Conservation of score mass just says that the outgoing scores from a state for a given observation are normalized.”<sup id="fnref:7"><a href="#fn:7" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[The Label Bias Problem](https://awni.github.io/label-bias/)">[7]</span></a></sup> The result is any inference process will bias towards states with fewer outgoing transitions.</li></ul><p>CRFs were designed to overcome this weakness.</p>
          </div>
<h2 id="vs-HMM"><a href="#vs-HMM" class="headerlink" title="vs HMM"></a>vs HMM</h2><p>unlike the HMM, the MEMM can condition on any useful feature of the input observation. In the HMM this wasn’t possible because the HMM is likelihood-based, hence would have needed to compute the likelihood of each feature of the observation.</p>
<p>$Y$ denotes the state sequence, $X$ denotes the observation.</p>
<p><strong>HMM</strong></p>
<script type="math/tex; mode=display">P(Y|X) = \prod_{i=1}^n P(x_i|y_i) \times \prod_{i=1}^n P(y_i|y_{i-1})</script><p><strong>MEMM</strong></p>
<script type="math/tex; mode=display">P(Y|X) = \prod_{i=1}^n P(y_i|y_{i-1},x_i)</script><p>To estimate the individual probability of a transition from a state $q’$ to a state $q$ producing an observation $o$, build a MaxEnt model:</p>
<script type="math/tex; mode=display">P(y|y',x) = \frac{1}{Z(x,y')} \exp(\sum_i w_i f_i(x,y))</script><hr>
<h1 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h1><h2 id="Linear-Chain-CRF"><a href="#Linear-Chain-CRF" class="headerlink" title="Linear-Chain CRF"></a>Linear-Chain CRF</h2><p>Modeling the distribution of a set of ouputs $y_{1:T}$ given an input vector $\mathbf{x}$.</p>
<script type="math/tex; mode=display">p(y_{1:T}|x, \mathbf{\lambda}) = \frac{1}{Z(\mathbf{x}, \mathbf{\lambda})} \prod_{t=2}^T \phi_t (y_t, y_{t-1}, \mathbf{x}, \mathbf{\lambda})</script><p>where $\lambda$ are the free parameters of the potentials, common form:</p>
<script type="math/tex; mode=display">\exp(\sum_{k=1}^K \lambda_k f_{k,t}(y_t,y_{t-1},\mathbf{x}))</script><p>where <script type="math/tex">f_{k,t}(y_t,y_{t-1}, \mathbf{x})</script> are <strong>features</strong>. </p>
<p>Thus,</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(y_{1:T}|x, \mathbf{\lambda}) &{}= \frac{1}{Z(\mathbf{x}, \mathbf{\lambda})} \prod_{t=2}^T \exp(\sum_{k=1}^K \lambda_k f_{k,t}(y_t,y_{t-1},\mathbf{x})) \\
&{}= \frac{1}{Z(\mathbf{x}, \mathbf{\lambda})}  \exp(\sum_{t=2}^T \sum_{k=1}^K \lambda_k f_{k,t}(y_t,y_{t-1},\mathbf{x}))
\end{aligned}</script><p>Given a set of input-output sequence pairs, <script type="math/tex">\mathbf{x}^n, y_{1:T}^n, n=\{1,2,...,N\}</script>. We can learn the parameters $\lambda$ by Maximum Likelihood. Under the i.i.d. data assumption, the log likelihood is:</p>
<script type="math/tex; mode=display">L(\mathbf{\lambda}) = \sum_{t,n} \sum_{k} \lambda_k f_k (y^n_t, y^n_{t-1}, x^n) - \sum_n \log Z(\mathbf{x}^n, \mathbf{\lambda})</script><p><strong>Cons</strong>: heavily rely on engineering features</p>
<hr>
<h1 id="BiLSTM-CRF"><a href="#BiLSTM-CRF" class="headerlink" title="BiLSTM-CRF"></a>BiLSTM-CRF</h1><p><strong>Intuition</strong>:<br>Capture both information from history (forward LSTM) and future (backward LSTM) using bi-LSTM; Also use <em>sentence level</em> tag information (after concatenation of both forward and backward LSTM/GRU hidden states in each time step) followed by the CRF model; Each output after concatenation can be regarded as a sentence level output.<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Huang, Z., Xu, W., & Yu, K. (2015). [Bidirectional LSTM-CRF Models for Sequence Tagging](https://arxiv.org/pdf/1508.01991.pdf). arXiv preprint arXiv:1508.01991.
">[2]</span></a></sup> CRF can help learn the boundary constraints, for example, ‘B-‘ is the start of a tag.</p>
<div class="note info">
            <p><strong>Pros</strong>: More robust, less affected by the removal of engineering features</p><p><strong>Cons</strong>: RNNs are not as GPU-efficient as CNNs in terms of training speed and efficiency.</p>
          </div>
<p>Let $y$ be the tag sequence and $x$ an input word sequence. Then, we have</p>
<script type="math/tex; mode=display">
P(y \vert x) = \frac{\exp (\textrm{score}(x,y))}{\sum_{y'} \exp(\textrm{score}(x,y'))}</script><p>where </p>
<script type="math/tex; mode=display">
\begin{aligned}
\textrm{score}(x,y) &{}=\sum_{i} \psi_i (x,y) \\
&{}= \sum_i \log \psi_{textrm{emit}} (y_i \rightarrow x_i) + \log \psi_{\textrm{trans}} (y_{i-1} \rightarrow y_i) \\
&{}= \sum_i h_i [y_i] + \mathbf{P}_{y_i, y_i-1}
\end{aligned}</script><p>In BiLSTM-CRFs, two potentials: emission and transition. The emission potential for the word $i$ comes from the hidden state of the BiLSTM at timestep $i$. The transition scores are stored at $\mathbf{P} \in \mathbb{R}^{|T| \times |T|}$. In the following implementation<sup id="fnref:8"><a href="#fn:8" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[PyTorch BiLSTM-CRF](https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html)
">[8]</span></a></sup>, $\mathbf{P}_{y_i, y_i-1}$ is the score of transitioning to tag $i-1$ from tag $i-1$.</p>
<p><img data-src="/notes/images/bilstm-crf.png" alt="BiLSTM-CRF"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.autograd <span class="keyword">as</span> autograd</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># util function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">argmax</span>(<span class="params">vec</span>):</span></span><br><span class="line">    <span class="comment"># return the argmax as a python int</span></span><br><span class="line">    _, idx = torch.<span class="built_in">max</span>(vec, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> idx.item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_sequence</span>(<span class="params">seq, to_ix</span>):</span></span><br><span class="line">    idxs = [to_ix[w] <span class="keyword">for</span> w <span class="keyword">in</span> seq]</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(idxs, dtype=torch.long)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute log sum exp in a numerically stable way for the forward algorithm</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_sum_exp</span>(<span class="params">vec</span>):</span></span><br><span class="line">    max_score = vec[<span class="number">0</span>, argmax(vec)]</span><br><span class="line">    max_score_broadcast = max_score.view(<span class="number">1</span>, -<span class="number">1</span>).expand(<span class="number">1</span>, vec.size()[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> max_score + \</span><br><span class="line">        torch.log(torch.<span class="built_in">sum</span>(torch.exp(vec - max_score_broadcast)))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># BiLSTM CRF</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BiLSTM_CRF</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, tag_to_ix, embedding_dim, hidden_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(BiLSTM_CRF, self).__init__()</span><br><span class="line">        self.embedding_dim = embedding_dim</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.tag_to_ix = tag_to_ix</span><br><span class="line">        self.tagset_size = <span class="built_in">len</span>(tag_to_ix)</span><br><span class="line"></span><br><span class="line">        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)</span><br><span class="line">        self.lstm = nn.LSTM(embedding_dim, hidden_dim // <span class="number">2</span>,</span><br><span class="line">                            num_layers=<span class="number">1</span>, bidirectional=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Maps the output of the LSTM into tag space.</span></span><br><span class="line">        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Matrix of transition parameters.  Entry i,j is the score of</span></span><br><span class="line">        <span class="comment"># transitioning *to* i *from* j.</span></span><br><span class="line">        <span class="comment"># $\mathbf&#123;P&#125;_&#123;y_i, y_i-1&#125;$</span></span><br><span class="line">        self.transitions = nn.Parameter(</span><br><span class="line">            torch.randn(self.tagset_size, self.tagset_size))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># These two statements enforce the constraint that we never transfer</span></span><br><span class="line">        <span class="comment"># to the start tag and we never transfer from the stop tag</span></span><br><span class="line">        self.transitions.data[tag_to_ix[START_TAG], :] = -<span class="number">10000</span></span><br><span class="line">        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -<span class="number">10000</span></span><br><span class="line"></span><br><span class="line">        self.hidden = self.init_hidden()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_hidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> (torch.randn(<span class="number">2</span>, <span class="number">1</span>, self.hidden_dim // <span class="number">2</span>),</span><br><span class="line">                torch.randn(<span class="number">2</span>, <span class="number">1</span>, self.hidden_dim // <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_forward_alg</span>(<span class="params">self, feats</span>):</span></span><br><span class="line">        <span class="comment"># Do the forward algorithm to compute the partition function</span></span><br><span class="line">        init_alphas = torch.full((<span class="number">1</span>, self.tagset_size), -<span class="number">10000.</span>)</span><br><span class="line">        <span class="comment"># START_TAG has all of the score.</span></span><br><span class="line">        init_alphas[<span class="number">0</span>][self.tag_to_ix[START_TAG]] = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Wrap in a variable so that we will get automatic backprop</span></span><br><span class="line">        forward_var = init_alphas</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate through the sentence</span></span><br><span class="line">        <span class="keyword">for</span> feat <span class="keyword">in</span> feats:</span><br><span class="line">            alphas_t = []  <span class="comment"># The forward tensors at this timestep</span></span><br><span class="line">            <span class="keyword">for</span> next_tag <span class="keyword">in</span> <span class="built_in">range</span>(self.tagset_size):</span><br><span class="line">                <span class="comment"># broadcast the emission score: it is the same regardless of</span></span><br><span class="line">                <span class="comment"># the previous tag</span></span><br><span class="line">                emit_score = feat[next_tag].view(</span><br><span class="line">                    <span class="number">1</span>, -<span class="number">1</span>).expand(<span class="number">1</span>, self.tagset_size)</span><br><span class="line">                <span class="comment"># the ith entry of trans_score is the score of transitioning to</span></span><br><span class="line">                <span class="comment"># next_tag from i</span></span><br><span class="line">                trans_score = self.transitions[next_tag].view(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># The ith entry of next_tag_var is the value for the</span></span><br><span class="line">                <span class="comment"># edge (i -&gt; next_tag) before we do log-sum-exp</span></span><br><span class="line">                next_tag_var = forward_var + trans_score + emit_score</span><br><span class="line">                <span class="comment"># The forward variable for this tag is log-sum-exp of all the</span></span><br><span class="line">                <span class="comment"># scores.</span></span><br><span class="line">                alphas_t.append(log_sum_exp(next_tag_var).view(<span class="number">1</span>))</span><br><span class="line">            forward_var = torch.cat(alphas_t).view(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]</span><br><span class="line">        alpha = log_sum_exp(terminal_var)</span><br><span class="line">        <span class="keyword">return</span> alpha</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_lstm_features</span>(<span class="params">self, sentence</span>):</span></span><br><span class="line">        self.hidden = self.init_hidden()</span><br><span class="line">        embeds = self.word_embeds(sentence).view(<span class="built_in">len</span>(sentence), <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        lstm_out, self.hidden = self.lstm(embeds, self.hidden)</span><br><span class="line">        lstm_out = lstm_out.view(<span class="built_in">len</span>(sentence), self.hidden_dim)</span><br><span class="line">        lstm_feats = self.hidden2tag(lstm_out)</span><br><span class="line">        <span class="keyword">return</span> lstm_feats</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_score_sentence</span>(<span class="params">self, feats, tags</span>):</span></span><br><span class="line">        <span class="comment"># Gives the score of a provided tag sequence</span></span><br><span class="line">        score = torch.zeros(<span class="number">1</span>)</span><br><span class="line">        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])</span><br><span class="line">        <span class="keyword">for</span> i, feat <span class="keyword">in</span> <span class="built_in">enumerate</span>(feats):</span><br><span class="line">            score = score + \</span><br><span class="line">                self.transitions[tags[i + <span class="number">1</span>], tags[i]] + feat[tags[i + <span class="number">1</span>]]</span><br><span class="line">        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-<span class="number">1</span>]]</span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_viterbi_decode</span>(<span class="params">self, feats</span>):</span></span><br><span class="line">        backpointers = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the viterbi variables in log space</span></span><br><span class="line">        init_vvars = torch.full((<span class="number">1</span>, self.tagset_size), -<span class="number">10000.</span>)</span><br><span class="line">        init_vvars[<span class="number">0</span>][self.tag_to_ix[START_TAG]] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward_var at step i holds the viterbi variables for step i-1</span></span><br><span class="line">        forward_var = init_vvars</span><br><span class="line">        <span class="keyword">for</span> feat <span class="keyword">in</span> feats:</span><br><span class="line">            bptrs_t = []  <span class="comment"># holds the backpointers for this step</span></span><br><span class="line">            viterbivars_t = []  <span class="comment"># holds the viterbi variables for this step</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> next_tag <span class="keyword">in</span> <span class="built_in">range</span>(self.tagset_size):</span><br><span class="line">                <span class="comment"># next_tag_var[i] holds the viterbi variable for tag i at the</span></span><br><span class="line">                <span class="comment"># previous step, plus the score of transitioning</span></span><br><span class="line">                <span class="comment"># from tag i to next_tag.</span></span><br><span class="line">                <span class="comment"># We don&#x27;t include the emission scores here because the max</span></span><br><span class="line">                <span class="comment"># does not depend on them (we add them in below)</span></span><br><span class="line">                next_tag_var = forward_var + self.transitions[next_tag]</span><br><span class="line">                best_tag_id = argmax(next_tag_var)</span><br><span class="line">                bptrs_t.append(best_tag_id)</span><br><span class="line">                viterbivars_t.append(next_tag_var[<span class="number">0</span>][best_tag_id].view(<span class="number">1</span>))</span><br><span class="line">            <span class="comment"># Now add in the emission scores, and assign forward_var to the set</span></span><br><span class="line">            <span class="comment"># of viterbi variables we just computed</span></span><br><span class="line">            forward_var = (torch.cat(viterbivars_t) + feat).view(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">            backpointers.append(bptrs_t)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Transition to STOP_TAG</span></span><br><span class="line">        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]</span><br><span class="line">        best_tag_id = argmax(terminal_var)</span><br><span class="line">        path_score = terminal_var[<span class="number">0</span>][best_tag_id]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Follow the back pointers to decode the best path.</span></span><br><span class="line">        best_path = [best_tag_id]</span><br><span class="line">        <span class="keyword">for</span> bptrs_t <span class="keyword">in</span> <span class="built_in">reversed</span>(backpointers):</span><br><span class="line">            best_tag_id = bptrs_t[best_tag_id]</span><br><span class="line">            best_path.append(best_tag_id)</span><br><span class="line">        <span class="comment"># Pop off the start tag (we dont want to return that to the caller)</span></span><br><span class="line">        start = best_path.pop()</span><br><span class="line">        <span class="keyword">assert</span> start == self.tag_to_ix[START_TAG]  <span class="comment"># Sanity check</span></span><br><span class="line">        best_path.reverse()</span><br><span class="line">        <span class="keyword">return</span> path_score, best_path</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">neg_log_likelihood</span>(<span class="params">self, sentence, tags</span>):</span></span><br><span class="line">        feats = self._get_lstm_features(sentence) <span class="comment"># emission scores</span></span><br><span class="line">        forward_score = self._forward_alg(feats) <span class="comment"># partition function</span></span><br><span class="line">        gold_score = self._score_sentence(feats, tags) <span class="comment"># correct score (numerator) $\exp(\psi(\cdot))$</span></span><br><span class="line">        <span class="keyword">return</span> forward_score - gold_score</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, sentence</span>):</span>  <span class="comment"># dont confuse this with _forward_alg above.</span></span><br><span class="line">        <span class="comment"># Get the emission scores from the BiLSTM</span></span><br><span class="line">        lstm_feats = self._get_lstm_features(sentence) <span class="comment"># emission scores</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Find the best path, given the features.</span></span><br><span class="line">        score, tag_seq = self._viterbi_decode(lstm_feats)</span><br><span class="line">        <span class="keyword">return</span> score, tag_seq</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="Stack-LSTM"><a href="#Stack-LSTM" class="headerlink" title="Stack-LSTM"></a>Stack-LSTM</h1><p>Char-based word representation indicates the word internal information, whilst pretrained word embeddings hold contextual text information.<br>Then, concat <strong>character-based word representation</strong> using Bi-LSTM and <strong>pretrained word embeddings</strong> as the final embeddings. <sup id="fnref:6"><a href="#fn:6" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). [Neural Architectures for Named Entity Recognition](https://arxiv.org/pdf/1603.01360.pdf). arXiv preprint arXiv:1603.01360.
">[6]</span></a></sup></p>
<p><img data-src="/notes/images/stack-LSTM.png" alt="Stack LSTM"></p>
<hr>
<h1 id="ID-CNN-CRF"><a href="#ID-CNN-CRF" class="headerlink" title="ID-CNN-CRF"></a>ID-CNN-CRF</h1><p><strong>Pros</strong>: fast, resource-efficient</p>
<p><strong>Dilation convolutions</strong>: </p>
<ul>
<li>context does not need to be consecutive</li>
<li><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>By stacking layers of dilated convolutions of <strong>exponentially dilation width</strong>, we can expand the size of the effective input width to cover the entire length of most sequences using only a few layers: the size of the effective input width for a token at layer <em>l</em> is now given by 2<sup>l+1</sup>-1 </p>

            <i class="fa fa-quote-right"></i>
          </blockquote></li>
<li>Let x<sub>t</sub> denotes the token in timestep t, W<sub>t</sub> is a sliding window of width $r$ tokens on either side of each token in the sequence, the conventional convolution output output c<sub>t</sub> is:<br>  <script type="math/tex">c_t= W_c \bigoplus_{k=0}^{r} x_{t} \pm k</script>,  where $\bigoplus$ is vector concatenation.</li>
<li>Dilated convolution is defined over a wider effective input width by skpping over \delta inputs, where $\delta$ is the dilation width. The dialated convolution is:  <script type="math/tex">c_t= W_c \bigoplus_{k=0}^{r} x_{t} \pm k \delta</script><br>  When $\delta$ is 1, dialated convolution is equivalent to a simple convolution.</li>
</ul>
<p><strong>Model</strong>: <strong>Stacked dilated CNNs</strong> <sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Strubell, E., Verga, P., Belanger, D., & McCallum, A. (2017). [Fast and accurate entity recognition with iterated dilated convolutions](https://arxiv.org/pdf/1702.02098). arXiv preprint arXiv:1702.02098.
">[3]</span></a></sup></p>
<p> Let the <script type="math/tex">j_{th}</script> dilated Conv layer of dilation width $\delta$ as <script type="math/tex">D_{\delta}^{(j)}</script>, <script type="math/tex">L_c</script> layers output:</p>
<script type="math/tex; mode=display">c_t^{(j)} = Relu(D_{2^{L_c-1}}^{(j-1)} c_t^{j-1})</script><p> And add a final dilation-1 layer to the stack:</p>
<script type="math/tex; mode=display">c_t^{L_c+1} = Relu(D_1^{(L_c)} c_t^{L_C})</script><p> Finally, apply the simple affine transformation $W_0$ to the final representation for each token <script type="math/tex">x_t</script>:</p>
<script type="math/tex; mode=display">h_T^{(L_b)} = W_O b_t^{L_b}</script><p>ID-CNNs generate token-wise representation (corresponding to logits for each token in RNNs) for each token. </p>
<p><strong>In comparison with BiLSTM-CRF</strong>  </p>
<p>Bi-LSTM or ID-CNNs calculates the logits for each token, whilst CRF layer capture the transmission probability of sequential inputs, i.e. use NNs to predict each token’s label independently, or apply <em>Viterbi inference</em> in a chain structured graphical model.</p>
<p><img data-src="/notes/images/ID-CNNs.png" alt="IDCNN"></p>
<hr>
<h1 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h1><p>Bidirectional Transformer for Language model, with pretraining methods of Masked Language Models (predicting randomly masked 15% tokens of each sentence) and next sentence prediction (to capture information of ajacent sentences).<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf?fbclid=IwAR3FQiWQzP7stmPWZ4kzrGmiUaN81UpiNeq4GWthrxmwgX0B9f1CvuXJC2E). arXiv preprint arXiv:1810.04805.
">[5]</span></a></sup></p>
<p><img data-src='/notes/images/BERT-NER.png' width='60%'/></p>
<hr>
<h1 id="Chinese-NER"><a href="#Chinese-NER" class="headerlink" title="Chinese NER"></a>Chinese NER</h1><div class="note warning">
            <p><strong>Chinese NER</strong><br><em>Word-based approach</em></p><ul><li>Intuitive pipeline: segmentation &rarr; NER</li><li>Suffer from segmentation error: <em>NE</em> imports OOV errors in segmentation, and incorrectly segmented entity boundaries lead to NER errors.</li></ul><p><em>Char-based approach</em></p><ul><li>Char-based NER outperform word-based approach in <em>Chinese</em> NER.</li><li><strong>Cons</strong>: Explicit word and word sequence information are not fully exploited.</li></ul><p><em>Solution</em>:</p><ul><li>Lattice LSTM: leverage both char sequence and lexicon word information.</li><li>FLAT</li></ul>
          </div>
<h2 id="Char-based-LSTM-CRF-model"><a href="#Char-based-LSTM-CRF-model" class="headerlink" title="Char-based LSTM-CRF model"></a>Char-based LSTM-CRF model</h2><ul>
<li><p>$\mathbf{x}_j^c = \mathbf{e}^c(c_j)$, where $\mathbf{e}^c$ denotes a char embedding lookup table.</p>
</li>
<li><p>Bi-LSTM output: $\mathbf{h_j^c} = [\overrightarrow{\mathbf{h}_j^c} ; \overleftarrow{\mathbf{h}_j^c}]$</p>
</li>
<li><p>CRF model use  $\mathbf{h_1^c}, \mathbf{h_2^c}, …,\mathbf{h_m^c}$ for sequence labelling.</p>
</li>
</ul>
<h3 id="Char-bi-char"><a href="#Char-bi-char" class="headerlink" title="Char + bi-char"></a>Char + bi-char</h3><p> Concat char embeddings with char-bigram embeddings.</p>
<script type="math/tex; mode=display">\mathbf{x_j^c} = [ \mathbf{e}^c(c_j) ; \mathbf{e}^b(c_j, c_{j+1}) ]</script><p>,where $\mathbf{e}^b$ denotes a char bigram lookup table</p>
<h3 id="Char-softword"><a href="#Char-softword" class="headerlink" title="Char + softword"></a>Char + softword</h3><ul>
<li>add segmentation as soft features by concatenating <strong>segmentation label embedding</strong> to char embeddings</li>
</ul>
<script type="math/tex; mode=display">\mathbf{x}_j^c = [\mathbf{e}^c (c_j) ; \mathbf{e^s}(seg(c_j)) ]</script><p>, where $\mathbf{e^s}$ signals the segmentation label on the char $c_j$ given by a word segmentor with <strong>BMES</strong> scheme.</p>
<p><img data-src="/notes/images/char-lstm.png" alt="Char LSTM"></p>
<h2 id="Word-based-model"><a href="#Word-based-model" class="headerlink" title="Word-based model"></a>Word-based model</h2><p>The input for each word $w_i$:  $\mathbf{x_i^w} = \mathbf{e}^w (w_i)$, where $e^w$ denotes the word embedding lookup table.<br>Then feed word embeddings into bi-directional LSTMs.</p>
<p><img data-src="/notes/images/word-lstm.png" alt="Word LSTM"></p>
<h3 id="Integrating-char-representations"><a href="#Integrating-char-representations" class="headerlink" title="Integrating char-representations"></a>Integrating char-representations</h3><blockquote>
<p>concat char-based word representation $\mathbf{x}_i^c$ (from cahr-LSTMs or char-CNNs) with pretrained word embeddings $\mathbf{e}^w(w_i)$:   $\mathbf{x}_i^w = [\mathbf{e}^w(w_i); \mathbf{x}_i^c]$</p>
</blockquote>
<p>1.<strong>Word + char bi-LSTMs</strong>: bi-LSTMs with chars as input in each time step.</p>
<script type="math/tex; mode=display">\mathbf{x}_i^c = [\overrightarrow{\mathbf{h}^c_{t(i,len(i))}} ; \overleftarrow{\mathbf{h}^c_{t(i,1)}}]</script><p>2.<strong>Word + char-uni-LSTM</strong></p>
<p>3.<strong>Word + char-CNNs</strong><br>Use char sequence of each word to obtain its char representation $\mathbf{x}_i^c$:</p>
<script type="math/tex; mode=display">\mathbf{x}_i^c = \max_{t(i,1)\leq j \leq t(i,len(i))}  (\mathbf{W}_{CNN}^T 
\bigl[ \begin{smallmatrix} \mathbf{e}^c (c_{j-\frac{k-1}{2}}) \\ ... \\ \mathbf{e}^c (c_{j+\frac{k-1}{2}}) \end{smallmatrix} \bigr] + \mathbf{b}_{CNN})</script><p>, where $ k=3 $ is the kernel size and $max$ denotes the max-pooling.</p>
<hr>
<h2 id="Lattice-LSTM"><a href="#Lattice-LSTM" class="headerlink" title="Lattice LSTM"></a>Lattice LSTM</h2><p>Let $s$ denotes input sequence.</p>
<ul>
<li><strong>Char-level</strong>: <script type="math/tex">s= c_1,c_2,...,c_m</script>, where <script type="math/tex">c_j</script> denotes the <script type="math/tex">j_{th}</script> character.</li>
<li><strong>Word-level</strong>: <script type="math/tex">s= w_1,w_2,...,w_n</script>, where <script type="math/tex">w_i</script> denotes the <script type="math/tex">i_{th}</script> token in the word sequence.</li>
</ul>
<p>In comparison with char-based model:</p>
<p>Char embedding:   $\mathbf{x}_j^c = \mathbf{e}^c(c_j)$</p>
<p>Basic recurrent LSTM:</p>
<script type="math/tex; mode=display">\left[\begin{array}{c} \mathbf{i}^c_j\\ \mathbf{o}^c_j    \\ \mathbf{f}^c_j    \\ \tilde{c}^c_j \end{array}\right]  = \left[\begin{array}{c} \sigma    \\ \sigma    \\ \sigma    \\ \tanh \end{array}\right]  (\mathbf{W}^{c^T} \left[\begin{array}{c} \mathbf{x}^c_j    \\ \mathbf{h}^c_{j-1}\end{array}\right] + \mathbf{b}^c)</script><script type="math/tex; mode=display">\mathbf{c}^c_j = \mathbf{f}^c_j \odot \mathbf{c}^c_{j-1} + \mathbf{i}^c_j \odot \tilde{c}^c_{j}</script><script type="math/tex; mode=display">\mathbf{h}_j^c = \mathbf{o}_j^c \odot \tanh(\mathbf{c}^c_j)</script><p>where $\mathbf{i}^c_j$, $\mathbf{f}^c_j$, $\mathbf{o}^c_j$ denotes a set of input, forget and output gates, respectively. $\mathbf{c}^c_j$ denotes the char cell vector, $\mathbf{h}^c_j$ denotes the hidden vector on each char $c_j$, $\mathbf{W}^{c^T}$, $\mathbf{b}^c$ are parameters.</p>
<p><img data-src="/notes/images/lattice-lstm-2.png" alt="Lattice-LSTM"></p>
<blockquote>
<p>The computation of cell vector <script type="math/tex">\mathbf{c}^c_j</script> considers lexicon subsequence <script type="math/tex">w_{b,e}^d</script> in the sentence<sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Zhang, Y., & Yang, J. (2018). [Chinese NER Using Lattice LSTM](https://arxiv.org/pdf/1805.02023.pdf). arXiv preprint arXiv:1805.02023.
">[4]</span></a></sup>. </p>
</blockquote>
<p>Each subsequence <script type="math/tex">w_{b,e}^{d}</script> is:</p>
<script type="math/tex; mode=display">\mathbf{x}_{b,e}^w = \mathbf{e}^w (w_{b,e}^d)</script><p>, where $\mathbf{e}^w$ denotes the word embedding lookup table.</p>
<p>The word cell <script type="math/tex">\mathbf{c}^w_{b,e}</script> represents the recurrent state of <script type="math/tex">\mathbf{x}^w_{b,e}</script> from the beginning of the sentence. The <script type="math/tex">\mathbf{c}^w_{b,e}</script> is:</p>
<script type="math/tex; mode=display">\left[\begin{array}{c} \mathbf{i}^w_{b,e}    \\ \mathbf{f}^w_{b,e}    \\ \tilde{c}^w_{b,e} \end{array}\right]  = \left[\begin{array}{c} \sigma    \\ \sigma    \\\tanh \end{array}\right]  (\mathbf{W}^{w^T} \left[\begin{array}{c} \mathbf{x}^w_{b,e}    \\ \mathbf{h}^c_b\end{array}\right] + \mathbf{b}^w)</script><script type="math/tex; mode=display">\mathbf{c}^w_{b,e} = \mathbf{f}^w_{b,e} \odot \mathbf{c}^c_b + \mathbf{i}^w_{b,e} \odot \tilde{c}^w_{b,e}</script><p>where <script type="math/tex">\mathbf{i}^w_{b,e}</script>, <script type="math/tex">\mathbf{f}^w_{b,e}</script> are input and forget gates. There is <strong>no output gate</strong> for word cells since <strong>labelling is performed only at the char level</strong>.</p>
<p>Here <script type="math/tex">\mathbf{c}^w_{b,e}</script> as an additional recurrent path for information flow for each <script type="math/tex">\mathbf{c}^c_{j}</script> . It applies an additional gate <script type="math/tex">\mathbf{i}^c_{b,e}</script> for each subsequence cell <script type="math/tex">\mathbf{c}^w_{b,e}</script> for controlling its contribution into <script type="math/tex">\mathbf{c}^w_{b,e}</script>:</p>
<script type="math/tex; mode=display">\mathbf{i}^c_{b,e} = \sigma (\mathbf{W}^{l^T} \left[\begin{array}{c} \mathbf{x}^c_{e}    \\ \mathbf{c}^w_{b,e} \end{array}\right] + \mathbf{b}^l)</script><p>Then cell vector <script type="math/tex">\mathbf{c}^c_j</script> is:</p>
<script type="math/tex; mode=display">\mathbf{c}^c_j = \mathbf{\alpha}_{j}^c \odot \tilde{\mathbf{c}}_j^c  + \Sigma_{b \in\{b'|w^d_{b',j}\} } \mathbf{\alpha}_{b,j}^c \odot \mathbf{c}^w_{b,j}</script><p>where the gate value <script type="math/tex">\mathbf{i}^c_{b,j}</script>, <script type="math/tex">\mathbf{i}^c_{j}</script> are normalised to <script type="math/tex">\mathbf{\alpha}_{b,j}^c</script> and <script type="math/tex">\mathbf{\alpha}_{j}^c</script> by setting the sum to 1:</p>
<script type="math/tex; mode=display">\mathbf{\alpha}_{b,j}^c  = \frac{\exp(\mathbf{i}^c_{b,j})}{\mathbf{i}^c_{j} + \Sigma_{b' \in {b''|w_{b'',j}^d}} \exp(\mathbf{i}^c_{b',j})}</script><script type="math/tex; mode=display">\mathbf{\alpha}_{j}^c  = \frac{\exp(\mathbf{i}^c_{j})}{\mathbf{i}^c_{j} + \Sigma_{b' \in {b''|w_{b'',j}^d}} \exp(\mathbf{i}^c_{b',j})}</script><script type="math/tex; mode=display">\mathbf{h}_j^c = \mathbf{o}_j^c \odot \tanh(\mathbf{c}^c_j)</script><p><img data-src="/notes/images/lattice-lstm.png" alt="Lattice LSTM"></p>
<p><strong>CRF decoding</strong></p>
<p>On top of <script type="math/tex">\mathbf{h}_1</script>, <script type="math/tex">\mathbf{h}_2</script>, …, <script type="math/tex">\mathbf{h}_{\tau}</script>, where $\tau$ is $n$ for char-based and lattice-based models and $m$ for word-based models. The probability of a label sequence <script type="math/tex">y = l_1, l_2, ... , l_{\tau}</script> is:</p>
<script type="math/tex; mode=display">P(y|s) = \frac{\exp(\Sigma_i (\mathbf{W}_{CRF}^{l_i} \mathbf{h}_i) +b_{CRF}^{(l_{i-1}, l_i)} )}{\Sigma_{y'} \exp(\Sigma_i (\mathbf{W}_{CRF}^{l'_i} \mathbf{h}_i) +b_{CRF}^{(l'_{i-1}, l'_i)} )}</script><p>where $y’$ denotes an arbitrary label sequence, <script type="math/tex">\mathbf{W}_{CRF}^{l_i}</script> is a model parameter specific to <script type="math/tex">l_i</script> and <script type="math/tex">b_{CRF}^{(l_{i-1}, l_i)}</script> is a bias specific to <script type="math/tex">l_{i-1}</script> and <script type="math/tex">l_i</script>.</p>
<p><strong>Sentence-level log-likelihood loss with L2 regularization</strong>:</p>
<script type="math/tex; mode=display">L = \sum_{i=1}^N log(P(y_i|s_i)) + \frac{\lambda}{2}||\Theta||^2</script><p>where $\lambda$ is the $L_2$ regularisation parameter and $\Theta$ represents the parameter set.</p>
<h2 id="FLAT"><a href="#FLAT" class="headerlink" title="FLAT"></a>FLAT</h2><p>Flat-Lattice Transformer (FLAT)</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Jurafsky, D., &amp; Martin, J. H. (2014). Speech and language processing (Vol. 3). London: Pearson.<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Huang, Z., Xu, W., &amp; Yu, K. (2015). <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1508.01991.pdf">Bidirectional LSTM-CRF Models for Sequence Tagging</a>. arXiv preprint arXiv:1508.01991.<a href="#fnref:2" rev="footnote"> ↩</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Strubell, E., Verga, P., Belanger, D., &amp; McCallum, A. (2017). <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1702.02098">Fast and accurate entity recognition with iterated dilated convolutions</a>. arXiv preprint arXiv:1702.02098.<a href="#fnref:3" rev="footnote"> ↩</a></span></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Zhang, Y., &amp; Yang, J. (2018). <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.02023.pdf">Chinese NER Using Lattice LSTM</a>. arXiv preprint arXiv:1805.02023.<a href="#fnref:4" rev="footnote"> ↩</a></span></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">5.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1810.04805.pdf?fbclid=IwAR3FQiWQzP7stmPWZ4kzrGmiUaN81UpiNeq4GWthrxmwgX0B9f1CvuXJC2E">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>. arXiv preprint arXiv:1810.04805.<a href="#fnref:5" rev="footnote"> ↩</a></span></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">6.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., &amp; Dyer, C. (2016). <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.01360.pdf">Neural Architectures for Named Entity Recognition</a>. arXiv preprint arXiv:1603.01360.<a href="#fnref:6" rev="footnote"> ↩</a></span></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">7.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://awni.github.io/label-bias/">The Label Bias Problem</a><a href="#fnref:7" rev="footnote"> ↩</a></span></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">8.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html">PyTorch BiLSTM-CRF</a><a href="#fnref:8" rev="footnote"> ↩</a></span></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">9.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/97676647">BiLSTM-CRF Explanation (in Chinese)</a><a href="#fnref:9" rev="footnote"> ↩</a></span></li></ol></div></div>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/notes/tags/NLP/" rel="tag"># NLP</a>
              <a href="/notes/tags/Survey/" rel="tag"># Survey</a>
              <a href="/notes/tags/NER/" rel="tag"># NER</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/notes/2018/11/27/ML/Data-augmentation-for-Deep-Learning-models/" rel="prev" title="Data Augmentation for Deep Learning Models">
      <i class="fa fa-chevron-left"></i> Data Augmentation for Deep Learning Models
    </a></div>
      <div class="post-nav-item">
    <a href="/notes/2018/12/02/ML/Active-learning-overview/" rel="next" title="Active Learning Overview">
      Active Learning Overview <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Hidden-Markov-Model"><span class="nav-number">1.</span> <span class="nav-text">Hidden Markov Model</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Maximum-Entropy-Markov-Model-MEMM"><span class="nav-number">2.</span> <span class="nav-text">Maximum-Entropy Markov Model (MEMM)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#vs-HMM"><span class="nav-number">2.1.</span> <span class="nav-text">vs HMM</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CRF"><span class="nav-number">3.</span> <span class="nav-text">CRF</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-Chain-CRF"><span class="nav-number">3.1.</span> <span class="nav-text">Linear-Chain CRF</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BiLSTM-CRF"><span class="nav-number">4.</span> <span class="nav-text">BiLSTM-CRF</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Stack-LSTM"><span class="nav-number">5.</span> <span class="nav-text">Stack-LSTM</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ID-CNN-CRF"><span class="nav-number">6.</span> <span class="nav-text">ID-CNN-CRF</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BERT"><span class="nav-number">7.</span> <span class="nav-text">BERT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Chinese-NER"><span class="nav-number">8.</span> <span class="nav-text">Chinese NER</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Char-based-LSTM-CRF-model"><span class="nav-number">8.1.</span> <span class="nav-text">Char-based LSTM-CRF model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Char-bi-char"><span class="nav-number">8.1.1.</span> <span class="nav-text">Char + bi-char</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Char-softword"><span class="nav-number">8.1.2.</span> <span class="nav-text">Char + softword</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Word-based-model"><span class="nav-number">8.2.</span> <span class="nav-text">Word-based model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Integrating-char-representations"><span class="nav-number">8.2.1.</span> <span class="nav-text">Integrating char-representations</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lattice-LSTM"><span class="nav-number">8.3.</span> <span class="nav-text">Lattice LSTM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FLAT"><span class="nav-number">8.4.</span> <span class="nav-text">FLAT</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#References"><span class="nav-number">9.</span> <span class="nav-text">References</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yekun Chai"
      src="/notes/images/ernie.jpeg">
  <p class="site-author-name" itemprop="name">Yekun Chai</p>
  <div class="site-description" itemprop="description">Language is not just words.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/notes/archives">
          <span class="site-state-item-count">70</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/notes/categories/">
          
        <span class="site-state-item-count">71</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/notes/tags/">
          
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://cyk1337.github.io" title="Home → https://cyk1337.github.io"><i class="fa fa-home fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/cyk1337" title="GitHub → https://github.com/cyk1337" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chaiyekun@gmail.com" title="E-Mail → mailto:chaiyekun@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/ychai1224" title="Twitter → https://twitter.com/ychai1224" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/9479335/cyk" title="StackOverflow → https://stackoverflow.com/users/9479335/cyk" rel="noopener" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i></a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/notes/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yekun Chai</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/notes/lib/anime.min.js"></script>
  <script src="/notes/lib/pjax/pjax.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script>
  <script src="//cdn.bootcdn.net/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/lozad.js/1.14.0/lozad.min.js"></script>
  <script src="/notes/lib/velocity/velocity.min.js"></script>
  <script src="/notes/lib/velocity/velocity.ui.min.js"></script>

<script src="/notes/js/utils.js"></script>

<script src="/notes/js/motion.js"></script>


<script src="/notes/js/schemes/muse.js"></script>


<script src="/notes/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/notes/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


  <!-- chaiyekun added  -->
   
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.29.3/moment.min.js"></script>
<script src="/notes/lib/moment-precise-range.min.js"></script>
<script>
  function timer() {
    var ages = moment.preciseDiff(moment(),moment(20180201,"YYYYMMDD"));
    ages = ages.replace(/years?/, "years");
    ages = ages.replace(/months?/, "months");
    ages = ages.replace(/days?/, "days");
    ages = ages.replace(/hours?/, "hours");
    ages = ages.replace(/minutes?/, "mins");
    ages = ages.replace(/seconds?/, "secs");
    ages = ages.replace(/\d+/g, '<span style="color:#1890ff">$&</span>');
    div.innerHTML = `I'm here for ${ages}`;
  }
  // create if not exists ==> fix multiple footer bugs ;)
  if ($('#time').length > 0) {
    var prev = document.getElementById("time");
    prev.remove();
  } 
  var div = document.createElement("div");
  div.setAttribute("id", "time");
  //插入到copyright之后
  var copyright = document.querySelector(".copyright");
  document.querySelector(".footer-inner").insertBefore(div, copyright.nextSibling);
 
  timer();
  setInterval("timer()",1000)
</script>

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://cyk0.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://cyk1337.github.io/notes/2018/11/29/NLP/NER/NER-overview/";
    this.page.identifier = "2018/11/29/NLP/NER/NER-overview/";
    this.page.title = "Named Entity Recognition Overview";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://cyk0.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

    </div>
<script src="/notes/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/notes/live2dw/assets/tororo.model.json"},"display":{"superSample":2,"width":96,"height":160,"position":"left","hOffset":0,"vOffset":-20},"mobile":{"show":false,"scale":0.1},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false});</script></body>
</html>
